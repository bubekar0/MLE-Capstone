# Arvato Customer Segmentation Project

## Table of Contents

1.
2. [Dependencies](https://github.com/bubekaro/MLE-Capstone#aaa)
2. [Description](https://github.com/bubekaro/MLE-Capstone#bbb)
3. [Data files](https://github.com/bubekaro/MLE-Capstone#ccc)
4. [Project Motivation](https://github.com/bubekaro/MLE-Capstone#ddd)
5. [File Description](https://github.com/bubekaro/MLE-Capstone#eee)
6. [Results](https://github.com/bubekaro/MLE-Capstone#fff)
7. [Licensing, Authors, Acknowledgements](https://github.com/bubekaro/MLE-Capstone#ggg)
8. [References](https://github.com/bubekaro/MLE-Capstone#hhh)

## Dependencies

* [Python 3*](https://www.python.org/)
* [NumPy](http://www.numpy.org/)
* [Pandas](http://pandas.pydata.org/)
* [matplotlib](https://matplotlib.org/)
* [Sciki-Learn](https://scikit-learn.org/stable/)

## Project Description
xxxxx

## Description
This Project is part of Data Science Nanodegree Program by Udacity in collaboration with Arvato Bertelsmann.

The Project is divided in the following Sections:

1. Part 0 - Get to Know the Data: xxx.

2. Part 1 - Customer Segmentation Report: xxx.

3. Part 2 - Supervised Learning Model: xxx.

## Data files

* `azdias`: demographics data for the general population of Germany; 
               891 211 persons (rows) x 366 features.

* `customers`: demographics data for customers of a mail-order company;
                191 652 persons (rows) x 369 features.

* `mailout_train`: Demographics data for individuals who were targets of a marketing campaign;
                   42982 persons and 367 features including response of people.

* `mailout_test`: Demographics data for individuals who were targets of a marketing campaign;
                  42833 persons and 366 features.

There are two more files which describes the attributes and its values. But the main datasets files are not available because of privacy of Arvato comapny's data.                  

## Project Motivation

Blah blah to fill in later

## File Description

  • `Capstone Arvato.ipynb` : All parts of the capstone project.

## Results
The main findings of the code can be found at this Customer Segemnetaion Report available [here.](https://uozon.com/)

## Licensing, Authors, Acknowledgements

  * [Udacity](https://www.udacity.com/) Capstone Project component to the MLE Nanodegree
  * [Arvato Bertelsmann](https://www.bertelsmann.com/divisions/arvato/#st-1) Data


## References
Jonathan Kropko, Ben Goodrich, Andrew Gelman & Jennifer Hill (October 4, 2013), page 2. ;
Retrieved from http://www.stat.columbia.edu/~gelman/research/published/MI_manuscript_RR.pdf

- Investigation of Multiple Imputation Methods for Categorical Variables;
Samantha Miranda (May 2020);
Retrieved from https://dc.etsu.edu/cgi/viewcontent.cgi?article=5204&context=etd

- Avoiding bias due to perfect prediction in multiple imputation of incomplete categorical variables;
Computational Statistics & Data Analysis,
Ian R White, Rhian Daniel, and Patrick Royston (October 1, 2010);
Retrieved from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3990447/

- Assumptions of Logistic Regression, Clearly Explained;
Kenneth Leung (October 4, 2021);
Retrieved from https://towardsdatascience.com/assumptions-of-logistic-regression-clearly-explained-44d85a22b290

- Decision Tree Classification in Python;
Avinash Naviani (December 28, 2018);
Retrieved from https://www.datacamp.com/community/tutorials/decision-tree-classification-python

- A Complete Guide to the Random Forest Algorithm;
Niklas Donges (July 22, 2021);
Retrieved from https://builtin.com/data-science/random-forest-algorithm

- AdaBoost Classifier in Python;
Avinash Naviani (November 20, 2018);
Retrieved from https://www.datacamp.com/community/tutorials/adaboost-classifier-python

- Understanding AdaBoost
Akash Desarda (January 17, 2019);
Retrieved from https://towardsdatascience.com/understanding-adaboost-2f94f22d5bfe

- A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning;
Jason Brownlee (September 9, 2016);
Retrieved from https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/

- Using XGBoost in Python;
Manish Pathak (November 8, 2019);
Retrieved from https://www.datacamp.com/community/tutorials/xgboost-in-python

- Complete Machine Learning Guide to Parameter Tuning in Gradient Boosting (GBM) in Python;
Aarshay Jain (February 21, 2016);
Retrieved from https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/
